{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyTNbfRD37eMQMijmwIsHl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/J-Princess/ML-AI-DS-Projects/blob/main/mas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-agent System Notebook"
      ],
      "metadata": {
        "id": "5I2guVnk47kK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This workbook shows the development of a simple Large Language Model (LLM) multi-agent system that will enable it to complete a given task with minimal intervention."
      ],
      "metadata": {
        "id": "9oH_fjGa4uOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9wes4iPz_xU"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-google-genai\n",
        "!pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "# from langchain_core.tools import tool\n",
        "from langchain_core.tools import StructuredTool\n",
        "\n",
        "from langgraph.graph import MessagesState\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.types import Send\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "from typing import Annotated, List, Literal\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import os, operator"
      ],
      "metadata": {
        "id": "dHLs7Qgm0C1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure API Keys to use\n",
        "API_KEY = ''\n",
        "\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = API_KEY"
      ],
      "metadata": {
        "id": "HHD415Uq0E06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure the LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n"
      ],
      "metadata": {
        "id": "o_4ErPRm0KGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yP15xFj10oEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Case Study: Maintenance of City Road Infrastructures\n",
        "\n",
        "The development of an LLM MAS for the automation of the process to determine when the Clifton Bridge requires maintenance."
      ],
      "metadata": {
        "id": "ECN2X1eV0oZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the path to the report files\n",
        "docs_path = \"./docs/\"\n",
        "def read_docs():\n",
        "    docs = []\n",
        "    for file in os.listdir(docs_path):\n",
        "\n",
        "        if file.endswith('.md'):\n",
        "            with open(os.path.join\n",
        "            (docs_path, file)) as f:\n",
        "                docs.append((file, f.read()))\n",
        "    return docs\n",
        "\n",
        "\n",
        "docs = read_docs()"
      ],
      "metadata": {
        "id": "RlShlNry0dkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define State And Required Types\n",
        "class ClassifiedCondition(BaseModel):\n",
        "    condition_details: str = Field(\n",
        "        description=\"Condition Details of the bridge classified by engineering perspective.\",\n",
        "    )\n",
        "    perspective: str = Field(\n",
        "        description=\"The specialist linked to the perspective of bridge condition, just a single word e.g. drainage, structural\",\n",
        "    )\n",
        "    section: str = Field(\n",
        "        description=\"The section or component the condition refers to, e.g. main deck, span 1, etc \",\n",
        "    )\n",
        "\n",
        "class ClassifiedConditionList(BaseModel):\n",
        "    classified_condition_list: List[ClassifiedCondition] = Field(\n",
        "        description=\"Condition Details of the bridge classified by engineering perspective.\",\n",
        "    )\n",
        "\n",
        "class ConditionState(BaseModel):\n",
        "    condition:str = Field(\n",
        "        description=\"Summary condition of the bridge by engineering perspective.\",\n",
        "    )\n",
        "    perspective: str = Field(\n",
        "        description=\"Engineering perspective.\",\n",
        "    )\n",
        "\n",
        "class Condition(BaseModel):\n",
        "    summary_condition:str = Field(\n",
        "        description=\"Summary condition of the bridge by engineering perspective.\",\n",
        "    )\n",
        "    perspective: str = Field(\n",
        "        description=\"Engineering perspective.\",\n",
        "    )\n",
        "    rating_condition: str = Field(\n",
        "        description=\"Rating of condition in scale 0 to 2.\",\n",
        "    )\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    docs: str\n",
        "    task: str\n",
        "    insights: str\n",
        "    assessment: str\n",
        "    result: str\n",
        "    classified_condition_list:ClassifiedConditionList\n",
        "    condition:Annotated[list,operator.add]"
      ],
      "metadata": {
        "id": "brJ9cvQj1V-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Document Screener Agent\n",
        "def doc_screening_officer(state: State) :\n",
        "    \"\"\"Extract key insights from documents for the task \"\"\"\n",
        "\n",
        "    base_prompt = f\"Concise but complete answer, no introduction. Extract key insights from: {state['docs']} to {state['task']}\"\n",
        "\n",
        "    if state.get(\"feedback\"):\n",
        "        msg = llm.invoke(\n",
        "            f\"{base_prompt} and taking into account the feedback: {state['feedback']}\"\n",
        "        )\n",
        "    else:\n",
        "        msg = llm.invoke(base_prompt)\n",
        "\n",
        "    return { \"insights\": msg.content }\n",
        "\n",
        "\n",
        "task_prompt = \"Determine maintenance timeframe for the bridge based on the condition of surface and drainage at March 2025\"\n",
        "state = {\"docs\": docs, \"task\": task_prompt}  # Initialize state with 'docs' and 'task'\n",
        "\n",
        "# First, generate the insights using doc_screening_officer\n",
        "insights = doc_screening_officer(state)\n",
        "\n",
        "# Update the state with the insights, preserving the 'task' key\n",
        "state.update(insights)\n",
        "\n",
        "# Now, you can call screening_checker with the updated state\n",
        "result = screening_checker(state)['result']\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "3COoEb531ewy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insight_requirements=\"concise, relevant, well supported and organised per perspective of condition of the bridge e.g.drainage, structural\"\n",
        "\n",
        "prompt_feedback = \"Assessment that insights extracted for the task are \"\n",
        "\n",
        "class Feedback(BaseModel):\n",
        "    result: Literal[\"Strong\", \"Weak\"] = Field(\n",
        "        description=f\"{prompt_feedback} {insight_requirements}\",\n",
        "    )\n",
        "    rationale: str = Field(\n",
        "        description=\"The rationale for the assessment\",\n",
        "    )\n",
        "\n",
        "evaluator = llm.with_structured_output(Feedback)"
      ],
      "metadata": {
        "id": "wG7_Nyys27Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def screening_checker(state:State):\n",
        "    \"\"\"Evaluate the insights extracted from the documents for the task\"\"\"\n",
        "\n",
        "    assessment = evaluator.invoke(f\"Check the insights: {state['insights']} are {insight_requirements} for {state['task']} and concisely explain why\")\n",
        "\n",
        "    return { \"result\": assessment.result, \"rationale\": assessment.rationale }"
      ],
      "metadata": {
        "id": "tFvP1gct3D3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Orchestrator Agent\n",
        "splitter =  llm.with_structured_output(ClassifiedConditionList)\n",
        "\n",
        "\n",
        "def orchestrator(state: State):\n",
        "    \"\"\"Orchestrator that organises the insights related to the condition of the bridge by perspective and section\"\"\"\n",
        "\n",
        "    orchestrator_prompt = f\"Extract condition details per section of the bridge from the insights {state['insights']} and organise into unique engineering perspectives. Multiple condition details can be assigned to the same perspective.  There is  a specialist type of engineer related to each perspective. \"\n",
        "    result = splitter.invoke(orchestrator_prompt)\n",
        "\n",
        "    return {\"classified_condition_list\":result.classified_condition_list}"
      ],
      "metadata": {
        "id": "_yVXj0uq3QmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Points\n",
        "\n",
        "def route_task(state: State):\n",
        "    \"\"\"route the task to the appropriate function\"\"\"\n",
        "    result = state.get(\"result\")\n",
        "    output = \"Rejected + Feedback\"\n",
        "    if result == \"Strong\":\n",
        "        output =  \"Accepted\"\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "_piTozVc3YDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign Specialist\n",
        "\n",
        "def assign_specialists(state: State):\n",
        "    \"\"\"Assign a specialist to each perspective of assessment\"\"\"\n",
        "\n",
        "    # group classified_condition_list by perspective\n",
        "    grouped_classified_condition_list = {}\n",
        "\n",
        "    stated = orchestrator(state)\n",
        "    for condition in stated['classified_condition_list']:\n",
        "        # Use square brackets to access or set the value associated with a key\n",
        "        if condition.perspective not in grouped_classified_condition_list:\n",
        "            grouped_classified_condition_list[condition.perspective] = []  # Initialize list if perspective is not in the dictionary\n",
        "        grouped_classified_condition_list[condition.perspective].append(condition)\n",
        "\n",
        "    # once grouped, we need to assign a specialist to each perspective\n",
        "    # e.g. drainage and  surface\n",
        "\n",
        "    # Note we use the Send function to call the \"assess_condition\"\n",
        "    # function in parallel for as many perspectives as we have\n",
        "\n",
        "    return [Send(\"assess_condition\",\n",
        "                 {\"condition\": grouped_classified_condition_list[s], \"perspective\":s}) for s in grouped_classified_condition_list.keys()]"
      ],
      "metadata": {
        "id": "91-gwEh63bmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assess Condition Agent\n",
        "def assess_condition(state: ConditionState):\n",
        "    \"\"\"Assess the condition of the asset from each perspective\"\"\"\n",
        "\n",
        "    condition_details = state[\"condition\"]\n",
        "    condition_details = \"\\n\".join([f\"- {cd}\" for cd in condition_details])\n",
        "\n",
        "    response = llm.with_structured_output(Condition).invoke(\n",
        "        [\n",
        "            SystemMessage(\n",
        "                content=f\"Assess the condition of the entire bridge from condition_details: {condition_details}.\"\n",
        "            ),\n",
        "            HumanMessage(\n",
        "                content=f\" From the perspective of {state['perspective']}\"\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return {\"condition\": [response]}"
      ],
      "metadata": {
        "id": "i4-wGpbD3g8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthesiser Agent\n",
        "def synthesiser(state: State):\n",
        "    \"\"\"Synthesise condition of the bridge. It calls the LLM to determine the maintenance timeframe given the state of the bridge\"\"\"\n",
        "\n",
        "    # List of condition of the bridge by perspective\n",
        "    condition = state[\"condition\"]\n",
        "\n",
        "    # Concatenate the condition of the bridge by perspective\n",
        "\n",
        "    output = \"\"\n",
        "\n",
        "    for perspective, assessment_result in condition.items():\n",
        "        output += f\"{perspective}: {assessment_result['summary']}. \"\n",
        "\n",
        "    prompt = f\"Given evidence of drainage and surface, determine maintenance timeframe given the state: {output}\"\n",
        "\n",
        "    result = llm.invoke(prompt)\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "7SKkqhpU3uW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Workflow graph definition\n",
        "mas_workflow = StateGraph(State)\n",
        "\n",
        "mas_workflow.add_node(\"doc_screening_officer\", doc_screening_officer)\n",
        "mas_workflow.add_node(\"screening_checker\", screening_checker)\n",
        "mas_workflow.add_node(\"orchestrator\", orchestrator)\n",
        "mas_workflow.add_node(\"assess_condition\", assess_condition)\n",
        "mas_workflow.add_node(\"synthesiser\", synthesiser)\n",
        "\n",
        "mas_workflow.add_edge(START, \"doc_screening_officer\")\n",
        "mas_workflow.add_edge(\"doc_screening_officer\", \"screening_checker\")\n",
        "# mas_workflow.add_edge(\"screening_checker\", \"orchestrator\")\n",
        "\n",
        "mas_workflow.add_conditional_edges(\"orchestrator\", assign_specialists, [\"assess_condition\"])\n",
        "# mas_workflow.add_edge(\"assign_specialists\", \"assess_condition\")\n",
        "mas_workflow.add_edge(\"assess_condition\", \"synthesiser\")\n",
        "mas_workflow.add_edge(\"synthesiser\", END)\n",
        "\n",
        "mas_workflow.add_conditional_edges(\"screening_checker\", route_task,\n",
        "                                   {\n",
        "                                     \"Accepted\": \"orchestrator\",\n",
        "                                      \"Rejected + Feedback\": \"doc_screening_officer\"\n",
        "                                   },\n",
        "                                  )\n",
        "\n",
        "\n",
        "# Compile the workflow\n",
        "compiled_wf = mas_worflow.compile()\n"
      ],
      "metadata": {
        "id": "8bWL76gv31Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the multi-agent workflow\n",
        "try:\n",
        "    display(Image(compiled_wf.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    # This requires some extra dependencies and is optional\n",
        "    pass"
      ],
      "metadata": {
        "id": "fMYTRigc4XBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the workflow\n",
        "\n",
        "task_prompt = \"Determine maintenance timeframe for the bridge based on the condition of surface and drainage at March 2025\"\n",
        "\n",
        "response = compiled_wf.invoke({\"docs\": docs,\"task\": task_prompt})\n",
        "\n",
        "print(response[\"condition\"])"
      ],
      "metadata": {
        "id": "KDPOiJ1g4aI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u1ZOejya4eYc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}